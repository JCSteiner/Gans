{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### GENERATIVE ADVERSARIAL NETWORKS\r\n",
    "## J. Steiner"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BACKGROUND"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Machine learning and nueral networks have been commonly used for supervised learning. That is, trying to make a predictive model with a training data set. Some common applications of supervised learning have been computer vision (think depositing checks with a cell phone), sentiment analysis (does an email sound happy or sad), and countless more. One application of supervised learning that had previously been possible, but not always working as well as would may be liked were generative models. Generative models are computer programs that take in a dataset, and create fabricated data for the dataset. For example, if I had a dataset of pictures of dogs, a generative model would output a picture of a dog which looked real, but did not actually exist and was not part of the dataset.\r\n",
    "\r\n",
    "Ian Goodfellow et al proposed Generative Adversarial Networks in 2014 with the goal of using supervised learning techniques to create a generative model. His idea was to use not one neural network to create the dataset, but two. One he called the generator, the generator takes a vector of random numbers and outputs fabricated data. The second is the discriminator, which takes either real data or fabricated data, and outputs a confidence level that the data is real as opposed to fake. This accurracy level of this confidence level allows the generator to be trained with supervised learning (specifically gradient descent) as we will train our generator to to minimize the success of the discriminator, but it can only reach an absolute minimum by generating data that is indistinguishable from the real data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### LOADING DEPENDENCIES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first step is to load in the library that will be used for the model implementation. This way we don't have to code neural network layers from scratch and can focus energy on re-inventing the wheel so to speak."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# imports pytorch dependencies that will be used for the math behind model implementation\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torchvision.datasets as datasets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torchvision.utils"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first thing that we need to do is create our generator and discriminator. We'll start with the generator. As a reminder, the generator takes a vector of noise (random numbers) and outputs a vector that is the same size as our fabricated data. The dataset I'll be using to illustrate this first example is called MNIST; it consists of 28x28 pixel grayscale images of handwritten numbers and was used in the original paper as an application of the framework. We'll be using a basic feed-forward fully connected network to take an input of the size of our noise vector, and output the size of our desired fabricated data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# generator class definition, being a subclass of nn.Module is required for a pytorch implementation\r\n",
    "class Generator(nn.Module):\r\n",
    "\r\n",
    "    # class constructor, runs automatically upon object creation\r\n",
    "    def __init__(self, noise_dims, output_dims):\r\n",
    "\r\n",
    "        # nois_dims   - the dimensionality of the input\r\n",
    "        # output_dims - the dimensionality of the output\r\n",
    "\r\n",
    "        # runs the class constructor for nn.Module, required for a pytorch implementation\r\n",
    "        super(Generator, self).__init__()\r\n",
    "\r\n",
    "        # we're defining the three layers of our model here. We take a noise vector and transform it\r\n",
    "        # to the size of our ouput vector. The generator block is defined below, but is just a fully\r\n",
    "        # connected layer with a ReLU activation function (to avoid the vanishing gradient problem) \r\n",
    "        self.block1 = self.generator_block(noise_dims, 256)\r\n",
    "        self.block2 = self.generator_block(256, 512)\r\n",
    "        self.block3 = self.generator_block(512, 1024)\r\n",
    "        self.output = nn.Sequential( nn.Linear(1024, output_dims), nn.Tanh())\r\n",
    "\r\n",
    "    # defines a layer of the generator, a fully connected layer with a ReLU activation\r\n",
    "    def generator_block(self, in_dims, out_dims):\r\n",
    "\r\n",
    "        # in_dims  - the dimensionality of the vector inputted into the \r\n",
    "        # out_dims - the dimensionality of the vector the layer will output\r\n",
    "\r\n",
    "        # returns a layer with the specified dimensionality\r\n",
    "        return nn.Sequential( nn.Linear(in_dims, out_dims),\r\n",
    "                              nn.ReLU() )\r\n",
    "\r\n",
    "    # a forward pass through the network\r\n",
    "    def forward(self, x):\r\n",
    "        \r\n",
    "        # pushes x through the network linearly without reshaping\r\n",
    "        # or normalization\r\n",
    "        x = self.block1(x)\r\n",
    "        x = self.block2(x)\r\n",
    "        x = self.block3(x)\r\n",
    "\r\n",
    "        # the final sigmoid activation is to scale the output from 0.0 to 1.0, this will be interpreted\r\n",
    "        # as the intensity of a pixel (how white a pixel is) when the vector is converted to an image\r\n",
    "        x = self.output(x)\r\n",
    "\r\n",
    "        # returns the output of the network\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next thing we'll do is create our discriminator. The discriminator will take an input the size of our real/fabricated data, and output a single value. This value is the confidence that the vector inputted was real data (1.0 means that it is 100% confident that the vector was real data and 0.0 means that the discriminator is 0% confident that the vector is real data AKA 100% confident the vector is fabricated)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# class definition\r\n",
    "class Discriminator(nn.Module):\r\n",
    "\r\n",
    "    # class constructor\r\n",
    "    def __init__(self, input_dims):\r\n",
    "        \r\n",
    "        # input_dims - \r\n",
    "\r\n",
    "        # super class constructor\r\n",
    "        super(Discriminator, self).__init__()\r\n",
    "\r\n",
    "        # we define three layers of our model here \r\n",
    "        self.block1 = self.discriminator_block(input_dims, 512)\r\n",
    "        self.block2 = self.discriminator_block(512, 128)\r\n",
    "        self.block3 = self.discriminator_block(128, 64)\r\n",
    "        self.output = nn.Sequential( nn.Linear(64, 1), nn.Sigmoid() )\r\n",
    "\r\n",
    "    # defines the layer we repeat for the discriminator\r\n",
    "    def discriminator_block(self, in_dims, out_dims):\r\n",
    "\r\n",
    "        # in_dims  - the dimensionality of the vector inputted into the layer\r\n",
    "        # out_dims - the dimensionality of the vector ouputted by the layer\r\n",
    "\r\n",
    "        # returns a fully connected layer, followed by a leaky ReLU activation\r\n",
    "        # and a dropout (randomly 0s out 3% of the output to control for overfitting)\r\n",
    "        return nn.Sequential( nn.Linear(in_dims, out_dims),\r\n",
    "                              nn.LeakyReLU(0.2),\r\n",
    "                              nn.Dropout(0.3) )\r\n",
    "\r\n",
    "    # a forward pass through the discriminator\r\n",
    "    def forward(self, x):\r\n",
    "\r\n",
    "        # pushes x through the network linearly without reshaping\r\n",
    "        # or normalization\r\n",
    "        x = self.block1(x)\r\n",
    "        x = self.block2(x)\r\n",
    "        x = self.block3(x)\r\n",
    "        x = self.output(x)\r\n",
    "\r\n",
    "        # returns the output of the network\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code below loads in the MNIST data that will be used for the first example. MNIST is such a common dataset, that code to download it exists within the pytorch library."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# transforms the dataset to a torch tensor (a tensor is a multi dimensinal vector)\r\n",
    "transform = transforms.Compose([ transforms.ToTensor(), \r\n",
    "                                 transforms.Normalize([ 0.5 ], [ 0.5 ]) ] )\r\n",
    "\r\n",
    "# loads in the dataset, it is so common that it can be loaded by the pytorch library\r\n",
    "dataset = datasets.MNIST(root = \"./dataset/\", train = True, transform = transform, download = True)\r\n",
    "\r\n",
    "# batches the data and wraps it into an iterable object\r\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defines the trianing function. After creating objects for the generator and discriminator models, optimizers, and error function we run through the GAN psuedo code.\r\n",
    "\r\n",
    "GAN Psuedocode:\r\n",
    "1. generate a batch of noise and get a batch of real data\r\n",
    "2. get the output of the noise from the generator\r\n",
    "3. train the output of the discriminator when given real data to be 1 and when given fake data to be 0\r\n",
    "4. train the generator to make the discriminator output 1\r\n",
    "\r\n",
    "Also to note: every epoch I take the first 16 training examples and the output of 16 fixed noise vectors and make them into a 4x8 grid of images. This way we see the generator's progress throughout training."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# defines the function to train the data\r\n",
    "def train(epochs, learning_rate, noise_dims):\r\n",
    "\r\n",
    "    # creates object for the generator and discriminator\r\n",
    "    gen = Generator(noise_dims, 28*28)\r\n",
    "    dis = Discriminator(28*28)\r\n",
    "\r\n",
    "    # creates the opitmizers for the generator and the discriminator\r\n",
    "    gen_optim = optim.Adam(gen.parameters(), lr=learning_rate, betas=(0.5, 0.999))\r\n",
    "    dis_optim = optim.Adam(dis.parameters(), lr=learning_rate, betas=(0.5, 0.999))\r\n",
    "\r\n",
    "    # defines the loss function for training, this stands for binary cross entropy\r\n",
    "    criterion = nn.BCELoss()\r\n",
    "\r\n",
    "    # defines a fixed batch of noise that will be run through the generator at given intervals\r\n",
    "    # this will show how the generator reacts to the same input, improving over time\r\n",
    "    fixed_noise_batch = torch.randn(16, noise_dims)\r\n",
    "\r\n",
    "    # loops through each epoch\r\n",
    "    for epoch in range(epochs):\r\n",
    "\r\n",
    "        # loops through each batch, taking the real data and discarding the label\r\n",
    "        for batch_idx, (real_batch, _) in enumerate(iter(loader)):\r\n",
    "            \r\n",
    "            # flattens out the image so it can be viewed like a vector\r\n",
    "            real_batch = real_batch.reshape(real_batch.shape[0], 28*28)\r\n",
    "\r\n",
    "            # zeros out model gradients\r\n",
    "            gen.zero_grad()\r\n",
    "            dis.zero_grad()\r\n",
    "\r\n",
    "            # creates a batch of noise with the same batch size as the real dat\r\n",
    "            noise_batch = torch.randn(real_batch.shape[0], noise_dims)\r\n",
    "\r\n",
    "            # a forward pass through the generator, a vector of fabricated data\r\n",
    "            fake_data_batch = gen(noise_batch)\r\n",
    "            # a forward pass through the discriminator, the confidence that the\r\n",
    "            # real batch is real for the line below, and the confidence that the\r\n",
    "            # fake data is real for the line below that\r\n",
    "            dis_out_real = dis(real_batch)\r\n",
    "            dis_out_fake = dis(fake_data_batch)\r\n",
    "            \r\n",
    "\r\n",
    "            # computes the error of the discriminator's confidence on the real data\r\n",
    "            loss_dis_real = criterion(dis_out_real, torch.ones_like(dis_out_real))\r\n",
    "            # computes the error of the discriminator's confidence on the fake data\r\n",
    "            loss_dis_fake = criterion(dis_out_fake, torch.zeros_like(dis_out_real))\r\n",
    "            # computes the total error of the discriminator\r\n",
    "            loss_dis_total = loss_dis_real + loss_dis_fake\r\n",
    "            \r\n",
    "            # runs a backward pass through the discriminator, calculating model gradients\r\n",
    "            # and retaining intermediate steps\r\n",
    "            loss_dis_total.backward(retain_graph = True)\r\n",
    "            # makes the discriminator learn\r\n",
    "            dis_optim.step()\r\n",
    "\r\n",
    "            # calculates the error and model gradients for what the generator would have to do\r\n",
    "            # to get the discriminator to think the fake data was real\r\n",
    "            new_out  = dis(fake_data_batch)\r\n",
    "            loss_gen = criterion(new_out, torch.ones_like(dis_out_real))\r\n",
    "            loss_gen.backward()\r\n",
    "            # makes the generator learn\r\n",
    "            gen_optim.step()\r\n",
    "\r\n",
    "            # every 100 batches\r\n",
    "            if batch_idx + 1 % 100 == 0:\r\n",
    "                \r\n",
    "                # print the progress\r\n",
    "                print(f\"Epoch [{epoch}/{epochs}] Batch [{batch_idx}/{len(loader)}]\")\r\n",
    "\r\n",
    "        # every 10 epochs\r\n",
    "        if epoch + 1 % 10 == 0:\r\n",
    "            # every epoch\r\n",
    "            # without model gradients\r\n",
    "            with torch.no_grad():\r\n",
    "\r\n",
    "                # generates new data based on fixed noise\r\n",
    "                # the + 1, / 2 scales it from (-1, 1) to (0, 1) just like the real\r\n",
    "                # images\r\n",
    "                fake = gen(fixed_noise_batch)\r\n",
    "\r\n",
    "                real_imgs = real_batch[:16].reshape(16, 1, 28, 28)\r\n",
    "                fake_imgs = fake[:16].reshape(16, 1, 28, 28)\r\n",
    "                grid_imgs = torch.cat((real_imgs, fake_imgs), dim = 0)\r\n",
    "\r\n",
    "                # creates an image grid of the outputted images, both real and fake\r\n",
    "                img_grid = torchvision.utils.make_grid(grid_imgs, normalize=True)\r\n",
    "\r\n",
    "                # saves the image grid\r\n",
    "                torchvision.utils.save_image(img_grid, './img' + str(epoch) + '.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# trains the model\r\n",
    "train(100, 0.001, 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [0/100] Batch [0/600]\n",
      "Epoch [0/100] Batch [100/600]\n",
      "Epoch [0/100] Batch [200/600]\n",
      "Epoch [0/100] Batch [300/600]\n",
      "Epoch [0/100] Batch [400/600]\n",
      "Epoch [0/100] Batch [500/600]\n",
      "Epoch [1/100] Batch [0/600]\n",
      "Epoch [1/100] Batch [100/600]\n",
      "Epoch [1/100] Batch [200/600]\n",
      "Epoch [1/100] Batch [300/600]\n",
      "Epoch [1/100] Batch [400/600]\n",
      "Epoch [1/100] Batch [500/600]\n",
      "Epoch [2/100] Batch [0/600]\n",
      "Epoch [2/100] Batch [100/600]\n",
      "Epoch [2/100] Batch [200/600]\n",
      "Epoch [2/100] Batch [300/600]\n",
      "Epoch [2/100] Batch [400/600]\n",
      "Epoch [2/100] Batch [500/600]\n",
      "Epoch [3/100] Batch [0/600]\n",
      "Epoch [3/100] Batch [100/600]\n",
      "Epoch [3/100] Batch [200/600]\n",
      "Epoch [3/100] Batch [300/600]\n",
      "Epoch [3/100] Batch [400/600]\n",
      "Epoch [3/100] Batch [500/600]\n",
      "Epoch [4/100] Batch [0/600]\n",
      "Epoch [4/100] Batch [100/600]\n",
      "Epoch [4/100] Batch [200/600]\n",
      "Epoch [4/100] Batch [300/600]\n",
      "Epoch [4/100] Batch [400/600]\n",
      "Epoch [4/100] Batch [500/600]\n",
      "Epoch [5/100] Batch [0/600]\n",
      "Epoch [5/100] Batch [100/600]\n",
      "Epoch [5/100] Batch [200/600]\n",
      "Epoch [5/100] Batch [300/600]\n",
      "Epoch [5/100] Batch [400/600]\n",
      "Epoch [5/100] Batch [500/600]\n",
      "Epoch [6/100] Batch [0/600]\n",
      "Epoch [6/100] Batch [100/600]\n",
      "Epoch [6/100] Batch [200/600]\n",
      "Epoch [6/100] Batch [300/600]\n",
      "Epoch [6/100] Batch [400/600]\n",
      "Epoch [6/100] Batch [500/600]\n",
      "Epoch [7/100] Batch [0/600]\n",
      "Epoch [7/100] Batch [100/600]\n",
      "Epoch [7/100] Batch [200/600]\n",
      "Epoch [7/100] Batch [300/600]\n",
      "Epoch [7/100] Batch [400/600]\n",
      "Epoch [7/100] Batch [500/600]\n",
      "Epoch [8/100] Batch [0/600]\n",
      "Epoch [8/100] Batch [100/600]\n",
      "Epoch [8/100] Batch [200/600]\n",
      "Epoch [8/100] Batch [300/600]\n",
      "Epoch [8/100] Batch [400/600]\n",
      "Epoch [8/100] Batch [500/600]\n",
      "Epoch [9/100] Batch [0/600]\n",
      "Epoch [9/100] Batch [100/600]\n",
      "Epoch [9/100] Batch [200/600]\n",
      "Epoch [9/100] Batch [300/600]\n",
      "Epoch [9/100] Batch [400/600]\n",
      "Epoch [9/100] Batch [500/600]\n",
      "Epoch [10/100] Batch [0/600]\n",
      "Epoch [10/100] Batch [100/600]\n",
      "Epoch [10/100] Batch [200/600]\n",
      "Epoch [10/100] Batch [300/600]\n",
      "Epoch [10/100] Batch [400/600]\n",
      "Epoch [10/100] Batch [500/600]\n",
      "Epoch [11/100] Batch [0/600]\n",
      "Epoch [11/100] Batch [100/600]\n",
      "Epoch [11/100] Batch [200/600]\n",
      "Epoch [11/100] Batch [300/600]\n",
      "Epoch [11/100] Batch [400/600]\n",
      "Epoch [11/100] Batch [500/600]\n",
      "Epoch [12/100] Batch [0/600]\n",
      "Epoch [12/100] Batch [100/600]\n",
      "Epoch [12/100] Batch [200/600]\n",
      "Epoch [12/100] Batch [300/600]\n",
      "Epoch [12/100] Batch [400/600]\n",
      "Epoch [12/100] Batch [500/600]\n",
      "Epoch [13/100] Batch [0/600]\n",
      "Epoch [13/100] Batch [100/600]\n",
      "Epoch [13/100] Batch [200/600]\n",
      "Epoch [13/100] Batch [300/600]\n",
      "Epoch [13/100] Batch [400/600]\n",
      "Epoch [13/100] Batch [500/600]\n",
      "Epoch [14/100] Batch [0/600]\n",
      "Epoch [14/100] Batch [100/600]\n",
      "Epoch [14/100] Batch [200/600]\n",
      "Epoch [14/100] Batch [300/600]\n",
      "Epoch [14/100] Batch [400/600]\n",
      "Epoch [14/100] Batch [500/600]\n",
      "Epoch [15/100] Batch [0/600]\n",
      "Epoch [15/100] Batch [100/600]\n",
      "Epoch [15/100] Batch [200/600]\n",
      "Epoch [15/100] Batch [300/600]\n",
      "Epoch [15/100] Batch [400/600]\n",
      "Epoch [15/100] Batch [500/600]\n",
      "Epoch [16/100] Batch [0/600]\n",
      "Epoch [16/100] Batch [100/600]\n",
      "Epoch [16/100] Batch [200/600]\n",
      "Epoch [16/100] Batch [300/600]\n",
      "Epoch [16/100] Batch [400/600]\n",
      "Epoch [16/100] Batch [500/600]\n",
      "Epoch [17/100] Batch [0/600]\n",
      "Epoch [17/100] Batch [100/600]\n",
      "Epoch [17/100] Batch [200/600]\n",
      "Epoch [17/100] Batch [300/600]\n",
      "Epoch [17/100] Batch [400/600]\n",
      "Epoch [17/100] Batch [500/600]\n",
      "Epoch [18/100] Batch [0/600]\n",
      "Epoch [18/100] Batch [100/600]\n",
      "Epoch [18/100] Batch [200/600]\n",
      "Epoch [18/100] Batch [300/600]\n",
      "Epoch [18/100] Batch [400/600]\n",
      "Epoch [18/100] Batch [500/600]\n",
      "Epoch [19/100] Batch [0/600]\n",
      "Epoch [19/100] Batch [100/600]\n",
      "Epoch [19/100] Batch [200/600]\n",
      "Epoch [19/100] Batch [300/600]\n",
      "Epoch [19/100] Batch [400/600]\n",
      "Epoch [19/100] Batch [500/600]\n",
      "Epoch [20/100] Batch [0/600]\n",
      "Epoch [20/100] Batch [100/600]\n",
      "Epoch [20/100] Batch [200/600]\n",
      "Epoch [20/100] Batch [300/600]\n",
      "Epoch [20/100] Batch [400/600]\n",
      "Epoch [20/100] Batch [500/600]\n",
      "Epoch [21/100] Batch [0/600]\n",
      "Epoch [21/100] Batch [100/600]\n",
      "Epoch [21/100] Batch [200/600]\n",
      "Epoch [21/100] Batch [300/600]\n",
      "Epoch [21/100] Batch [400/600]\n",
      "Epoch [21/100] Batch [500/600]\n",
      "Epoch [22/100] Batch [0/600]\n",
      "Epoch [22/100] Batch [100/600]\n",
      "Epoch [22/100] Batch [200/600]\n",
      "Epoch [22/100] Batch [300/600]\n",
      "Epoch [22/100] Batch [400/600]\n",
      "Epoch [22/100] Batch [500/600]\n",
      "Epoch [23/100] Batch [0/600]\n",
      "Epoch [23/100] Batch [100/600]\n",
      "Epoch [23/100] Batch [200/600]\n",
      "Epoch [23/100] Batch [300/600]\n",
      "Epoch [23/100] Batch [400/600]\n",
      "Epoch [23/100] Batch [500/600]\n",
      "Epoch [24/100] Batch [0/600]\n",
      "Epoch [24/100] Batch [100/600]\n",
      "Epoch [24/100] Batch [200/600]\n",
      "Epoch [24/100] Batch [300/600]\n",
      "Epoch [24/100] Batch [400/600]\n",
      "Epoch [24/100] Batch [500/600]\n",
      "Epoch [25/100] Batch [0/600]\n",
      "Epoch [25/100] Batch [100/600]\n",
      "Epoch [25/100] Batch [200/600]\n",
      "Epoch [25/100] Batch [300/600]\n",
      "Epoch [25/100] Batch [400/600]\n",
      "Epoch [25/100] Batch [500/600]\n",
      "Epoch [26/100] Batch [0/600]\n",
      "Epoch [26/100] Batch [100/600]\n",
      "Epoch [26/100] Batch [200/600]\n",
      "Epoch [26/100] Batch [300/600]\n",
      "Epoch [26/100] Batch [400/600]\n",
      "Epoch [26/100] Batch [500/600]\n",
      "Epoch [27/100] Batch [0/600]\n",
      "Epoch [27/100] Batch [100/600]\n",
      "Epoch [27/100] Batch [200/600]\n",
      "Epoch [27/100] Batch [300/600]\n",
      "Epoch [27/100] Batch [400/600]\n",
      "Epoch [27/100] Batch [500/600]\n",
      "Epoch [28/100] Batch [0/600]\n",
      "Epoch [28/100] Batch [100/600]\n",
      "Epoch [28/100] Batch [200/600]\n",
      "Epoch [28/100] Batch [300/600]\n",
      "Epoch [28/100] Batch [400/600]\n",
      "Epoch [28/100] Batch [500/600]\n",
      "Epoch [29/100] Batch [0/600]\n",
      "Epoch [29/100] Batch [100/600]\n",
      "Epoch [29/100] Batch [200/600]\n",
      "Epoch [29/100] Batch [300/600]\n",
      "Epoch [29/100] Batch [400/600]\n",
      "Epoch [29/100] Batch [500/600]\n",
      "Epoch [30/100] Batch [0/600]\n",
      "Epoch [30/100] Batch [100/600]\n",
      "Epoch [30/100] Batch [200/600]\n",
      "Epoch [30/100] Batch [300/600]\n",
      "Epoch [30/100] Batch [400/600]\n",
      "Epoch [30/100] Batch [500/600]\n",
      "Epoch [31/100] Batch [0/600]\n",
      "Epoch [31/100] Batch [100/600]\n",
      "Epoch [31/100] Batch [200/600]\n",
      "Epoch [31/100] Batch [300/600]\n",
      "Epoch [31/100] Batch [400/600]\n",
      "Epoch [31/100] Batch [500/600]\n",
      "Epoch [32/100] Batch [0/600]\n",
      "Epoch [32/100] Batch [100/600]\n",
      "Epoch [32/100] Batch [200/600]\n",
      "Epoch [32/100] Batch [300/600]\n",
      "Epoch [32/100] Batch [400/600]\n",
      "Epoch [32/100] Batch [500/600]\n",
      "Epoch [33/100] Batch [0/600]\n",
      "Epoch [33/100] Batch [100/600]\n",
      "Epoch [33/100] Batch [200/600]\n",
      "Epoch [33/100] Batch [300/600]\n",
      "Epoch [33/100] Batch [400/600]\n",
      "Epoch [33/100] Batch [500/600]\n",
      "Epoch [34/100] Batch [0/600]\n",
      "Epoch [34/100] Batch [100/600]\n",
      "Epoch [34/100] Batch [200/600]\n",
      "Epoch [34/100] Batch [300/600]\n",
      "Epoch [34/100] Batch [400/600]\n",
      "Epoch [34/100] Batch [500/600]\n",
      "Epoch [35/100] Batch [0/600]\n",
      "Epoch [35/100] Batch [100/600]\n",
      "Epoch [35/100] Batch [200/600]\n",
      "Epoch [35/100] Batch [300/600]\n",
      "Epoch [35/100] Batch [400/600]\n",
      "Epoch [35/100] Batch [500/600]\n",
      "Epoch [36/100] Batch [0/600]\n",
      "Epoch [36/100] Batch [100/600]\n",
      "Epoch [36/100] Batch [200/600]\n",
      "Epoch [36/100] Batch [300/600]\n",
      "Epoch [36/100] Batch [400/600]\n",
      "Epoch [36/100] Batch [500/600]\n",
      "Epoch [37/100] Batch [0/600]\n",
      "Epoch [37/100] Batch [100/600]\n",
      "Epoch [37/100] Batch [200/600]\n",
      "Epoch [37/100] Batch [300/600]\n",
      "Epoch [37/100] Batch [400/600]\n",
      "Epoch [37/100] Batch [500/600]\n",
      "Epoch [38/100] Batch [0/600]\n",
      "Epoch [38/100] Batch [100/600]\n",
      "Epoch [38/100] Batch [200/600]\n",
      "Epoch [38/100] Batch [300/600]\n",
      "Epoch [38/100] Batch [400/600]\n",
      "Epoch [38/100] Batch [500/600]\n",
      "Epoch [39/100] Batch [0/600]\n",
      "Epoch [39/100] Batch [100/600]\n",
      "Epoch [39/100] Batch [200/600]\n",
      "Epoch [39/100] Batch [300/600]\n",
      "Epoch [39/100] Batch [400/600]\n",
      "Epoch [39/100] Batch [500/600]\n",
      "Epoch [40/100] Batch [0/600]\n",
      "Epoch [40/100] Batch [100/600]\n",
      "Epoch [40/100] Batch [200/600]\n",
      "Epoch [40/100] Batch [300/600]\n",
      "Epoch [40/100] Batch [400/600]\n",
      "Epoch [40/100] Batch [500/600]\n",
      "Epoch [41/100] Batch [0/600]\n",
      "Epoch [41/100] Batch [100/600]\n",
      "Epoch [41/100] Batch [200/600]\n",
      "Epoch [41/100] Batch [300/600]\n",
      "Epoch [41/100] Batch [400/600]\n",
      "Epoch [41/100] Batch [500/600]\n",
      "Epoch [42/100] Batch [0/600]\n",
      "Epoch [42/100] Batch [100/600]\n",
      "Epoch [42/100] Batch [200/600]\n",
      "Epoch [42/100] Batch [300/600]\n",
      "Epoch [42/100] Batch [400/600]\n",
      "Epoch [42/100] Batch [500/600]\n",
      "Epoch [43/100] Batch [0/600]\n",
      "Epoch [43/100] Batch [100/600]\n",
      "Epoch [43/100] Batch [200/600]\n",
      "Epoch [43/100] Batch [300/600]\n",
      "Epoch [43/100] Batch [400/600]\n",
      "Epoch [43/100] Batch [500/600]\n",
      "Epoch [44/100] Batch [0/600]\n",
      "Epoch [44/100] Batch [100/600]\n",
      "Epoch [44/100] Batch [200/600]\n",
      "Epoch [44/100] Batch [300/600]\n",
      "Epoch [44/100] Batch [400/600]\n",
      "Epoch [44/100] Batch [500/600]\n",
      "Epoch [45/100] Batch [0/600]\n",
      "Epoch [45/100] Batch [100/600]\n",
      "Epoch [45/100] Batch [200/600]\n",
      "Epoch [45/100] Batch [300/600]\n",
      "Epoch [45/100] Batch [400/600]\n",
      "Epoch [45/100] Batch [500/600]\n",
      "Epoch [46/100] Batch [0/600]\n",
      "Epoch [46/100] Batch [100/600]\n",
      "Epoch [46/100] Batch [200/600]\n",
      "Epoch [46/100] Batch [300/600]\n",
      "Epoch [46/100] Batch [400/600]\n",
      "Epoch [46/100] Batch [500/600]\n",
      "Epoch [47/100] Batch [0/600]\n",
      "Epoch [47/100] Batch [100/600]\n",
      "Epoch [47/100] Batch [200/600]\n",
      "Epoch [47/100] Batch [300/600]\n",
      "Epoch [47/100] Batch [400/600]\n",
      "Epoch [47/100] Batch [500/600]\n",
      "Epoch [48/100] Batch [0/600]\n",
      "Epoch [48/100] Batch [100/600]\n",
      "Epoch [48/100] Batch [200/600]\n",
      "Epoch [48/100] Batch [300/600]\n",
      "Epoch [48/100] Batch [400/600]\n",
      "Epoch [48/100] Batch [500/600]\n",
      "Epoch [49/100] Batch [0/600]\n",
      "Epoch [49/100] Batch [100/600]\n",
      "Epoch [49/100] Batch [200/600]\n",
      "Epoch [49/100] Batch [300/600]\n",
      "Epoch [49/100] Batch [400/600]\n",
      "Epoch [49/100] Batch [500/600]\n",
      "Epoch [50/100] Batch [0/600]\n",
      "Epoch [50/100] Batch [100/600]\n",
      "Epoch [50/100] Batch [200/600]\n",
      "Epoch [50/100] Batch [300/600]\n",
      "Epoch [50/100] Batch [400/600]\n",
      "Epoch [50/100] Batch [500/600]\n",
      "Epoch [51/100] Batch [0/600]\n",
      "Epoch [51/100] Batch [100/600]\n",
      "Epoch [51/100] Batch [200/600]\n",
      "Epoch [51/100] Batch [300/600]\n",
      "Epoch [51/100] Batch [400/600]\n",
      "Epoch [51/100] Batch [500/600]\n",
      "Epoch [52/100] Batch [0/600]\n",
      "Epoch [52/100] Batch [100/600]\n",
      "Epoch [52/100] Batch [200/600]\n",
      "Epoch [52/100] Batch [300/600]\n",
      "Epoch [52/100] Batch [400/600]\n",
      "Epoch [52/100] Batch [500/600]\n",
      "Epoch [53/100] Batch [0/600]\n",
      "Epoch [53/100] Batch [100/600]\n",
      "Epoch [53/100] Batch [200/600]\n",
      "Epoch [53/100] Batch [300/600]\n",
      "Epoch [53/100] Batch [400/600]\n",
      "Epoch [53/100] Batch [500/600]\n",
      "Epoch [54/100] Batch [0/600]\n",
      "Epoch [54/100] Batch [100/600]\n",
      "Epoch [54/100] Batch [200/600]\n",
      "Epoch [54/100] Batch [300/600]\n",
      "Epoch [54/100] Batch [400/600]\n",
      "Epoch [54/100] Batch [500/600]\n",
      "Epoch [55/100] Batch [0/600]\n",
      "Epoch [55/100] Batch [100/600]\n",
      "Epoch [55/100] Batch [200/600]\n",
      "Epoch [55/100] Batch [300/600]\n",
      "Epoch [55/100] Batch [400/600]\n",
      "Epoch [55/100] Batch [500/600]\n",
      "Epoch [56/100] Batch [0/600]\n",
      "Epoch [56/100] Batch [100/600]\n",
      "Epoch [56/100] Batch [200/600]\n",
      "Epoch [56/100] Batch [300/600]\n",
      "Epoch [56/100] Batch [400/600]\n",
      "Epoch [56/100] Batch [500/600]\n",
      "Epoch [57/100] Batch [0/600]\n",
      "Epoch [57/100] Batch [100/600]\n",
      "Epoch [57/100] Batch [200/600]\n",
      "Epoch [57/100] Batch [300/600]\n",
      "Epoch [57/100] Batch [400/600]\n",
      "Epoch [57/100] Batch [500/600]\n",
      "Epoch [58/100] Batch [0/600]\n",
      "Epoch [58/100] Batch [100/600]\n",
      "Epoch [58/100] Batch [200/600]\n",
      "Epoch [58/100] Batch [300/600]\n",
      "Epoch [58/100] Batch [400/600]\n",
      "Epoch [58/100] Batch [500/600]\n",
      "Epoch [59/100] Batch [0/600]\n",
      "Epoch [59/100] Batch [100/600]\n",
      "Epoch [59/100] Batch [200/600]\n",
      "Epoch [59/100] Batch [300/600]\n",
      "Epoch [59/100] Batch [400/600]\n",
      "Epoch [59/100] Batch [500/600]\n",
      "Epoch [60/100] Batch [0/600]\n",
      "Epoch [60/100] Batch [100/600]\n",
      "Epoch [60/100] Batch [200/600]\n",
      "Epoch [60/100] Batch [300/600]\n",
      "Epoch [60/100] Batch [400/600]\n",
      "Epoch [60/100] Batch [500/600]\n",
      "Epoch [61/100] Batch [0/600]\n",
      "Epoch [61/100] Batch [100/600]\n",
      "Epoch [61/100] Batch [200/600]\n",
      "Epoch [61/100] Batch [300/600]\n",
      "Epoch [61/100] Batch [400/600]\n",
      "Epoch [61/100] Batch [500/600]\n",
      "Epoch [62/100] Batch [0/600]\n",
      "Epoch [62/100] Batch [100/600]\n",
      "Epoch [62/100] Batch [200/600]\n",
      "Epoch [62/100] Batch [300/600]\n",
      "Epoch [62/100] Batch [400/600]\n",
      "Epoch [62/100] Batch [500/600]\n",
      "Epoch [63/100] Batch [0/600]\n",
      "Epoch [63/100] Batch [100/600]\n",
      "Epoch [63/100] Batch [200/600]\n",
      "Epoch [63/100] Batch [300/600]\n",
      "Epoch [63/100] Batch [400/600]\n",
      "Epoch [63/100] Batch [500/600]\n",
      "Epoch [64/100] Batch [0/600]\n",
      "Epoch [64/100] Batch [100/600]\n",
      "Epoch [64/100] Batch [200/600]\n",
      "Epoch [64/100] Batch [300/600]\n",
      "Epoch [64/100] Batch [400/600]\n",
      "Epoch [64/100] Batch [500/600]\n",
      "Epoch [65/100] Batch [0/600]\n",
      "Epoch [65/100] Batch [100/600]\n",
      "Epoch [65/100] Batch [200/600]\n",
      "Epoch [65/100] Batch [300/600]\n",
      "Epoch [65/100] Batch [400/600]\n",
      "Epoch [65/100] Batch [500/600]\n",
      "Epoch [66/100] Batch [0/600]\n",
      "Epoch [66/100] Batch [100/600]\n",
      "Epoch [66/100] Batch [200/600]\n",
      "Epoch [66/100] Batch [300/600]\n",
      "Epoch [66/100] Batch [400/600]\n",
      "Epoch [66/100] Batch [500/600]\n",
      "Epoch [67/100] Batch [0/600]\n",
      "Epoch [67/100] Batch [100/600]\n",
      "Epoch [67/100] Batch [200/600]\n",
      "Epoch [67/100] Batch [300/600]\n",
      "Epoch [67/100] Batch [400/600]\n",
      "Epoch [67/100] Batch [500/600]\n",
      "Epoch [68/100] Batch [0/600]\n",
      "Epoch [68/100] Batch [100/600]\n",
      "Epoch [68/100] Batch [200/600]\n",
      "Epoch [68/100] Batch [300/600]\n",
      "Epoch [68/100] Batch [400/600]\n",
      "Epoch [68/100] Batch [500/600]\n",
      "Epoch [69/100] Batch [0/600]\n",
      "Epoch [69/100] Batch [100/600]\n",
      "Epoch [69/100] Batch [200/600]\n",
      "Epoch [69/100] Batch [300/600]\n",
      "Epoch [69/100] Batch [400/600]\n",
      "Epoch [69/100] Batch [500/600]\n",
      "Epoch [70/100] Batch [0/600]\n",
      "Epoch [70/100] Batch [100/600]\n",
      "Epoch [70/100] Batch [200/600]\n",
      "Epoch [70/100] Batch [300/600]\n",
      "Epoch [70/100] Batch [400/600]\n",
      "Epoch [70/100] Batch [500/600]\n",
      "Epoch [71/100] Batch [0/600]\n",
      "Epoch [71/100] Batch [100/600]\n",
      "Epoch [71/100] Batch [200/600]\n",
      "Epoch [71/100] Batch [300/600]\n",
      "Epoch [71/100] Batch [400/600]\n",
      "Epoch [71/100] Batch [500/600]\n",
      "Epoch [72/100] Batch [0/600]\n",
      "Epoch [72/100] Batch [100/600]\n",
      "Epoch [72/100] Batch [200/600]\n",
      "Epoch [72/100] Batch [300/600]\n",
      "Epoch [72/100] Batch [400/600]\n",
      "Epoch [72/100] Batch [500/600]\n",
      "Epoch [73/100] Batch [0/600]\n",
      "Epoch [73/100] Batch [100/600]\n",
      "Epoch [73/100] Batch [200/600]\n",
      "Epoch [73/100] Batch [300/600]\n",
      "Epoch [73/100] Batch [400/600]\n",
      "Epoch [73/100] Batch [500/600]\n",
      "Epoch [74/100] Batch [0/600]\n",
      "Epoch [74/100] Batch [100/600]\n",
      "Epoch [74/100] Batch [200/600]\n",
      "Epoch [74/100] Batch [300/600]\n",
      "Epoch [74/100] Batch [400/600]\n",
      "Epoch [74/100] Batch [500/600]\n",
      "Epoch [75/100] Batch [0/600]\n",
      "Epoch [75/100] Batch [100/600]\n",
      "Epoch [75/100] Batch [200/600]\n",
      "Epoch [75/100] Batch [300/600]\n",
      "Epoch [75/100] Batch [400/600]\n",
      "Epoch [75/100] Batch [500/600]\n",
      "Epoch [76/100] Batch [0/600]\n",
      "Epoch [76/100] Batch [100/600]\n",
      "Epoch [76/100] Batch [200/600]\n",
      "Epoch [76/100] Batch [300/600]\n",
      "Epoch [76/100] Batch [400/600]\n",
      "Epoch [76/100] Batch [500/600]\n",
      "Epoch [77/100] Batch [0/600]\n",
      "Epoch [77/100] Batch [100/600]\n",
      "Epoch [77/100] Batch [200/600]\n",
      "Epoch [77/100] Batch [300/600]\n",
      "Epoch [77/100] Batch [400/600]\n",
      "Epoch [77/100] Batch [500/600]\n",
      "Epoch [78/100] Batch [0/600]\n",
      "Epoch [78/100] Batch [100/600]\n",
      "Epoch [78/100] Batch [200/600]\n",
      "Epoch [78/100] Batch [300/600]\n",
      "Epoch [78/100] Batch [400/600]\n",
      "Epoch [78/100] Batch [500/600]\n",
      "Epoch [79/100] Batch [0/600]\n",
      "Epoch [79/100] Batch [100/600]\n",
      "Epoch [79/100] Batch [200/600]\n",
      "Epoch [79/100] Batch [300/600]\n",
      "Epoch [79/100] Batch [400/600]\n",
      "Epoch [79/100] Batch [500/600]\n",
      "Epoch [80/100] Batch [0/600]\n",
      "Epoch [80/100] Batch [100/600]\n",
      "Epoch [80/100] Batch [200/600]\n",
      "Epoch [80/100] Batch [300/600]\n",
      "Epoch [80/100] Batch [400/600]\n",
      "Epoch [80/100] Batch [500/600]\n",
      "Epoch [81/100] Batch [0/600]\n",
      "Epoch [81/100] Batch [100/600]\n",
      "Epoch [81/100] Batch [200/600]\n",
      "Epoch [81/100] Batch [300/600]\n",
      "Epoch [81/100] Batch [400/600]\n",
      "Epoch [81/100] Batch [500/600]\n",
      "Epoch [82/100] Batch [0/600]\n",
      "Epoch [82/100] Batch [100/600]\n",
      "Epoch [82/100] Batch [200/600]\n",
      "Epoch [82/100] Batch [300/600]\n",
      "Epoch [82/100] Batch [400/600]\n",
      "Epoch [82/100] Batch [500/600]\n",
      "Epoch [83/100] Batch [0/600]\n",
      "Epoch [83/100] Batch [100/600]\n",
      "Epoch [83/100] Batch [200/600]\n",
      "Epoch [83/100] Batch [300/600]\n",
      "Epoch [83/100] Batch [400/600]\n",
      "Epoch [83/100] Batch [500/600]\n",
      "Epoch [84/100] Batch [0/600]\n",
      "Epoch [84/100] Batch [100/600]\n",
      "Epoch [84/100] Batch [200/600]\n",
      "Epoch [84/100] Batch [300/600]\n",
      "Epoch [84/100] Batch [400/600]\n",
      "Epoch [84/100] Batch [500/600]\n",
      "Epoch [85/100] Batch [0/600]\n",
      "Epoch [85/100] Batch [100/600]\n",
      "Epoch [85/100] Batch [200/600]\n",
      "Epoch [85/100] Batch [300/600]\n",
      "Epoch [85/100] Batch [400/600]\n",
      "Epoch [85/100] Batch [500/600]\n",
      "Epoch [86/100] Batch [0/600]\n",
      "Epoch [86/100] Batch [100/600]\n",
      "Epoch [86/100] Batch [200/600]\n",
      "Epoch [86/100] Batch [300/600]\n",
      "Epoch [86/100] Batch [400/600]\n",
      "Epoch [86/100] Batch [500/600]\n",
      "Epoch [87/100] Batch [0/600]\n",
      "Epoch [87/100] Batch [100/600]\n",
      "Epoch [87/100] Batch [200/600]\n",
      "Epoch [87/100] Batch [300/600]\n",
      "Epoch [87/100] Batch [400/600]\n",
      "Epoch [87/100] Batch [500/600]\n",
      "Epoch [88/100] Batch [0/600]\n",
      "Epoch [88/100] Batch [100/600]\n",
      "Epoch [88/100] Batch [200/600]\n",
      "Epoch [88/100] Batch [300/600]\n",
      "Epoch [88/100] Batch [400/600]\n",
      "Epoch [88/100] Batch [500/600]\n",
      "Epoch [89/100] Batch [0/600]\n",
      "Epoch [89/100] Batch [100/600]\n",
      "Epoch [89/100] Batch [200/600]\n",
      "Epoch [89/100] Batch [300/600]\n",
      "Epoch [89/100] Batch [400/600]\n",
      "Epoch [89/100] Batch [500/600]\n",
      "Epoch [90/100] Batch [0/600]\n",
      "Epoch [90/100] Batch [100/600]\n",
      "Epoch [90/100] Batch [200/600]\n",
      "Epoch [90/100] Batch [300/600]\n",
      "Epoch [90/100] Batch [400/600]\n",
      "Epoch [90/100] Batch [500/600]\n",
      "Epoch [91/100] Batch [0/600]\n",
      "Epoch [91/100] Batch [100/600]\n",
      "Epoch [91/100] Batch [200/600]\n",
      "Epoch [91/100] Batch [300/600]\n",
      "Epoch [91/100] Batch [400/600]\n",
      "Epoch [91/100] Batch [500/600]\n",
      "Epoch [92/100] Batch [0/600]\n",
      "Epoch [92/100] Batch [100/600]\n",
      "Epoch [92/100] Batch [200/600]\n",
      "Epoch [92/100] Batch [300/600]\n",
      "Epoch [92/100] Batch [400/600]\n",
      "Epoch [92/100] Batch [500/600]\n",
      "Epoch [93/100] Batch [0/600]\n",
      "Epoch [93/100] Batch [100/600]\n",
      "Epoch [93/100] Batch [200/600]\n",
      "Epoch [93/100] Batch [300/600]\n",
      "Epoch [93/100] Batch [400/600]\n",
      "Epoch [93/100] Batch [500/600]\n",
      "Epoch [94/100] Batch [0/600]\n",
      "Epoch [94/100] Batch [100/600]\n",
      "Epoch [94/100] Batch [200/600]\n",
      "Epoch [94/100] Batch [300/600]\n",
      "Epoch [94/100] Batch [400/600]\n",
      "Epoch [94/100] Batch [500/600]\n",
      "Epoch [95/100] Batch [0/600]\n",
      "Epoch [95/100] Batch [100/600]\n",
      "Epoch [95/100] Batch [200/600]\n",
      "Epoch [95/100] Batch [300/600]\n",
      "Epoch [95/100] Batch [400/600]\n",
      "Epoch [95/100] Batch [500/600]\n",
      "Epoch [96/100] Batch [0/600]\n",
      "Epoch [96/100] Batch [100/600]\n",
      "Epoch [96/100] Batch [200/600]\n",
      "Epoch [96/100] Batch [300/600]\n",
      "Epoch [96/100] Batch [400/600]\n",
      "Epoch [96/100] Batch [500/600]\n",
      "Epoch [97/100] Batch [0/600]\n",
      "Epoch [97/100] Batch [100/600]\n",
      "Epoch [97/100] Batch [200/600]\n",
      "Epoch [97/100] Batch [300/600]\n",
      "Epoch [97/100] Batch [400/600]\n",
      "Epoch [97/100] Batch [500/600]\n",
      "Epoch [98/100] Batch [0/600]\n",
      "Epoch [98/100] Batch [100/600]\n",
      "Epoch [98/100] Batch [200/600]\n",
      "Epoch [98/100] Batch [300/600]\n",
      "Epoch [98/100] Batch [400/600]\n",
      "Epoch [98/100] Batch [500/600]\n",
      "Epoch [99/100] Batch [0/600]\n",
      "Epoch [99/100] Batch [100/600]\n",
      "Epoch [99/100] Batch [200/600]\n",
      "Epoch [99/100] Batch [300/600]\n",
      "Epoch [99/100] Batch [400/600]\n",
      "Epoch [99/100] Batch [500/600]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "# generator class definition\r\n",
    "class Generator(nn.Module):\r\n",
    "\r\n",
    "    # generator class constructor\r\n",
    "    def __init__(self, noise_dims):\r\n",
    "        \r\n",
    "        # noise_dims - the dimensionality of the noise inputted\r\n",
    "\r\n",
    "        # runs the super class constructor\r\n",
    "        super(Generator, self).__init__()\r\n",
    "\r\n",
    "        # transforms a noise vector from a 100 dimension vector to a vector that can be reshaped into\r\n",
    "        # a tensor of size (512, 4, 4) which is 512 layers of a 4x4 image\r\n",
    "        self.linear = nn.Linear(noise_dims, 256*4*4)\r\n",
    "\r\n",
    "        # runs through convolution transpose blocks to scale from 512 channels to 64 channels\r\n",
    "        self.block1 = self.generator_block(256, 128)\r\n",
    "        self.block2 = self.generator_block(128, 64)\r\n",
    "\r\n",
    "        # runs through one more convolution transpose and scales a 64x64 3 channel (rgb) image\r\n",
    "        self.output = nn.Sequential( nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh() )\r\n",
    "\r\n",
    "    # defines the generator block\r\n",
    "    def generator_block(self, in_channels, out_channels):\r\n",
    "\r\n",
    "        # a convolutional transpose layer, with a batch normalization and a ReLU activation\r\n",
    "        return nn.Sequential( nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1),\r\n",
    "                              nn.BatchNorm2d(out_channels),\r\n",
    "                              nn.ReLU() )\r\n",
    "\r\n",
    "    # a forward pass through the network\r\n",
    "    def forward(self, x):\r\n",
    "\r\n",
    "        # transforms a noise vector to something that can be reshaped into an image\r\n",
    "        x = self.linear(x.view(x.shape[0], 100))\r\n",
    "\r\n",
    "        # reshapes x into a 4x4 image with 512 channels\r\n",
    "        x = x.reshape(x.shape[0], 256, 4, 4)\r\n",
    "\r\n",
    "        # runs through 3 generator blocks\r\n",
    "        x = self.block1(x)\r\n",
    "        x = self.block2(x)\r\n",
    "\r\n",
    "        # outputs to a 64x64 3 channel image\r\n",
    "        x = self.output(x)\r\n",
    "\r\n",
    "        # returns the output of the network\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "# defines the discriminator class\r\n",
    "class Discriminator(nn.Module):\r\n",
    "\r\n",
    "    # class constructor\r\n",
    "    def __init__(self):\r\n",
    "\r\n",
    "        # runs the super class constructor\r\n",
    "        super(Discriminator, self).__init__()\r\n",
    "\r\n",
    "        # the first convolutional layer, downscales the inputted 64x64 3 channel image\r\n",
    "        # this is not a block because we do not want to batch normalize on the first layer\r\n",
    "        self.conv   = nn.Sequential( nn.ConvTranspose2d(3, 64, 4, 2, 1),\r\n",
    "                                     nn.LeakyReLU(0.2) )\r\n",
    "\r\n",
    "        # runs through 3 discriminator blocks\r\n",
    "        self.block1 = self.discriminator_block(64, 128)\r\n",
    "        self.block2 = self.discriminator_block(128, 256)\r\n",
    "\r\n",
    "        # downscales to a 1 channel image\r\n",
    "        self.conv2  = nn.ConvTranspose2d(256, 1, 4, 2, 0)\r\n",
    "\r\n",
    "        # outputs a single value, the confidence that the inputted image was real\r\n",
    "        self.output = nn.Sequential( nn.Linear(34 * 34, 1), nn.Sigmoid() )\r\n",
    "\r\n",
    "    # defines a discriminator block\r\n",
    "    def discriminator_block(self, in_channels, out_channels):\r\n",
    "\r\n",
    "        # consists of a convolutional layer, batch normalization, and leaky ReLU activation\r\n",
    "        return nn.Sequential( nn.Conv2d(in_channels, out_channels, 4, 2, 1),\r\n",
    "                              nn.BatchNorm2d(out_channels),\r\n",
    "                              nn.LeakyReLU(0.2))\r\n",
    "\r\n",
    "    # forward pass through the network\r\n",
    "    def forward(self, x):\r\n",
    "\r\n",
    "        # first convolutional layer\r\n",
    "        x = self.conv(x)\r\n",
    "\r\n",
    "        # 3 discriminator blocks\r\n",
    "        x = self.block1(x)\r\n",
    "        x = self.block2(x)\r\n",
    "\r\n",
    "        # downscales the image with a second convolution\r\n",
    "        x = self.conv2(x)\r\n",
    "\r\n",
    "        # flattens out the image and outputs to a single value\r\n",
    "        x = x.view(x.shape[0], 34*34)\r\n",
    "        x = self.output(x)\r\n",
    "        \r\n",
    "        # returns the output of the network\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# initializes the weights of the model parameters\r\n",
    "def init_weights(model):\r\n",
    "\r\n",
    "    # loops through each layer in the model and initializes as a normal distribution with a mean\r\n",
    "    # of 0.0 and a standard deviation of 0.02\r\n",
    "    for m in model.modules():\r\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\r\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\r\n",
    "\r\n",
    "\r\n",
    "# defines a transformation pipeline for the dataset we load in\r\n",
    "transform = transforms.Compose(\r\n",
    "        [ transforms.Resize((32, 32)),\r\n",
    "          transforms.ToTensor(),\r\n",
    "          transforms.Normalize([ 0.5 for _ in range(3) ], [ 0.5 for _ in range(3) ]) ] )\r\n",
    "\r\n",
    "# loads in the CIFAR10 dataset, full color 32x32 images of animals and objects\r\n",
    "dataset = torchvision.datasets.CIFAR10(root = \"./dataset/\", train = True, transform = transform, download = True)\r\n",
    "\r\n",
    "# creates a data loader object\r\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# defines the function to train the data\r\n",
    "def train(epochs, learning_rate, noise_dims):\r\n",
    "\r\n",
    "    # creates object for the generator and discriminator\r\n",
    "    gen = Generator(noise_dims)\r\n",
    "    dis = Discriminator()\r\n",
    "\r\n",
    "    # creates the opitmizers for the generator and the discriminator\r\n",
    "    gen_optim = optim.Adam(gen.parameters(), lr=learning_rate, betas=(0.5, 0.999))\r\n",
    "    dis_optim = optim.Adam(dis.parameters(), lr=learning_rate, betas=(0.5, 0.999))\r\n",
    "\r\n",
    "    # defines the loss function for training, this stands for binary cross entropy\r\n",
    "    criterion = nn.BCELoss()\r\n",
    "\r\n",
    "    # defines a fixed batch of noise that will be run through the generator at given intervals\r\n",
    "    # this will show how the generator reacts to the same input, improving over time\r\n",
    "    fixed_noise_batch = torch.randn(16, noise_dims)\r\n",
    "\r\n",
    "    # loops through each epoch\r\n",
    "    for epoch in range(epochs):\r\n",
    "\r\n",
    "        # loops through each batch, taking the real data and discarding the label\r\n",
    "        for batch_idx, (real_batch, _) in enumerate(iter(loader)):\r\n",
    "\r\n",
    "            # zeros out model gradients\r\n",
    "            gen.zero_grad()\r\n",
    "            dis.zero_grad()\r\n",
    "\r\n",
    "            # creates a batch of noise with the same batch size as the real dat\r\n",
    "            noise_batch = torch.randn(real_batch.shape[0], noise_dims)\r\n",
    "\r\n",
    "            # a forward pass through the generator, a vector of fabricated data\r\n",
    "            fake_data_batch = gen(noise_batch)\r\n",
    "            # a forward pass through the discriminator, the confidence that the\r\n",
    "            # real batch is real for the line below, and the confidence that the\r\n",
    "            # fake data is real for the line below that\r\n",
    "            dis_out_real = dis(real_batch)\r\n",
    "            dis_out_fake = dis(fake_data_batch)\r\n",
    "            \r\n",
    "\r\n",
    "            # computes the error of the discriminator's confidence on the real data\r\n",
    "            loss_dis_real = criterion(dis_out_real, torch.ones_like(dis_out_real))\r\n",
    "            # computes the error of the discriminator's confidence on the fake data\r\n",
    "            loss_dis_fake = criterion(dis_out_fake, torch.zeros_like(dis_out_real))\r\n",
    "            # computes the total error of the discriminator\r\n",
    "            loss_dis_total = loss_dis_real + loss_dis_fake\r\n",
    "            \r\n",
    "            # runs a backward pass through the discriminator, calculating model gradients\r\n",
    "            # and retaining intermediate steps\r\n",
    "            loss_dis_total.backward(retain_graph = True)\r\n",
    "            # makes the discriminator learn\r\n",
    "            dis_optim.step()\r\n",
    "\r\n",
    "            # calculates the error and model gradients for what the generator would have to do\r\n",
    "            # to get the discriminator to think the fake data was real\r\n",
    "            new_out  = dis(fake_data_batch)\r\n",
    "            loss_gen = criterion(new_out, torch.ones_like(dis_out_real))\r\n",
    "            loss_gen.backward()\r\n",
    "            # makes the generator learn\r\n",
    "            gen_optim.step()\r\n",
    "\r\n",
    "            # every 100 batches\r\n",
    "            if batch_idx % 100 == 0:\r\n",
    "                \r\n",
    "                # print the progress\r\n",
    "                print(f\"Epoch [{epoch}/{epochs}] Batch [{batch_idx}/{len(loader)}]\")\r\n",
    "\r\n",
    "        # every 10 epochs\r\n",
    "        if epoch % 10 == 0:\r\n",
    "            # every epoch\r\n",
    "            # without model gradients\r\n",
    "            with torch.no_grad():\r\n",
    "\r\n",
    "                # generates new data based on fixed noise\r\n",
    "                # the + 1, / 2 scales it from (-1, 1) to (0, 1) just like the real\r\n",
    "                # images\r\n",
    "                fake = gen(fixed_noise_batch)\r\n",
    "\r\n",
    "                grid_imgs = torch.cat((real_batch[:16], fake[:16]), dim = 0)\r\n",
    "\r\n",
    "                # creates an image grid of the outputted images, both real and fake\r\n",
    "                img_grid = torchvision.utils.make_grid(grid_imgs, normalize=True)\r\n",
    "\r\n",
    "                # saves the image grid\r\n",
    "                torchvision.utils.save_image(img_grid, './img' + str(epoch) + '.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'm not going to spend the weeks that it would take to train this here.\r\n",
    "\r\n",
    "Another interesting application that could combine conditional GANs and the DCGANs was done in a the DeepArt paper. This would take in 2 input images, 1 would be a real life photograph, the other a famous art piece, and some noise. The Generator would then output the picture, stylized according to the famous art piece. This shows some of the exciting places that conditional GANs can go."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A next step for GANs is to apply it to natural language processing. The current Gold Standard Architecture for NLP is the Transformer. Created by Google's AI lab in late 2017, the transformer improves off the recurrent neural networks which had been used previously for NLP problems. The TransGAN paper uses transformers for more image generation tasks, however it would be theoretically possible to do this for NLP GAN tasks. I've been working on something to do just that and have seen moderate success. That's a little outside the scope of this notebook because of just how involved it is. It's also something that is a little too resource intensive for me to realistic run it on my personal computer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "6748769364378ebf249890eb6895b0869d15f8c9ff692159230eb6f5429612f4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}